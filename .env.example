# API Configuration
API_KEY=your_api_key_here
API_ENDPOINT=https://api.openai.com/v1
DEFAULT_MODEL=gpt-4o-mini

# Stage-Specific Models
INTENT_MODEL=gpt-4o-mini
PLANNER_MODEL=gpt-4o

# Multi-Resource Summarizer (MRS) Model Configuration
# Default model used when no content type is specified
MRS_MODEL_DEFAULT=gpt-4o-mini

# Content-Specific MRS Models (optional)
# Uncomment and configure models for different content types:
# MRS_MODEL_CODE=gpt-4o-mini        # For Stack Overflow, GitHub, code documentation
# MRS_MODEL_RESEARCH=gpt-4o         # For arXiv, research papers, academic content
# MRS_MODEL_NEWS=gpt-4o-mini        # For news articles, blogs, media
# MRS_MODEL_DOCUMENTATION=gpt-4o    # For technical documentation
# MRS_MODEL_GENERAL=gpt-4o-mini     # Fallback for general content

# How content type detection works:
# 1. URL heuristics check domain patterns (arxiv.org -> research, github.com -> code)
# 2. Falls back to MRS_MODEL_DEFAULT if no content-specific model is configured
# 3. Uses MRS_MODEL_GENERAL if configured, otherwise MRS_MODEL_DEFAULT

CONTEXT_MODEL=gpt-4o-mini
REFLECTION_MODEL=gpt-4o
REPORT_MODEL=gpt-4o

# Search Configuration (Serper.dev provides both search and scraping)
SERPER_API_KEY=your_serper_api_key  # Required for web search and scraping fallback
# Perplexity Search API (optional; use if SEARCH_PROVIDER=PERPLEXITY)
PERPLEXITY_API_KEY=your_perplexity_api_key
# Choose provider: SERP (Serper), TAVILY, or PERPLEXITY
SEARCH_PROVIDER=SERP  # Options: SERP, TAVILY, PERPLEXITY
TAVILY_API_KEY=your_tavily_api_key  # Optional: enables higher rate limits
SEARCH_RESULTS_PER_QUERY=10  # Number of search results to request per query (5-20 recommended)
RERANK_TOP_K_URL=0.3   # Ratio of search results to scrape (0.0-1.0)
RERANK_TOP_K_SUM=0.5   # Ratio of summaries to include in report (0.0-1.0)

# Vector Database Configuration
VECTOR_DB_PATH=./research_db.sqlite
EMBEDDING_MODEL=text-embedding-3-small

# Reranker Configuration (optional)
# RERANKER_URL=https://api.jina.ai/v1/rerank
# RERANKER_MODEL=jina-reranker-v2-base-multilingual
# RERANKER_API_KEY=your_reranker_api_key
# USE_RERANKER=true

# Verification Configuration (Optional - adds ~30-60s and ~$0.04-0.05 per report)
# VERIFY_CLAIMS=true  # Enable claim verification stage
# VERIFY_MODEL=gpt-4o-mini  # Model for verification (cheap is fine)
# VERIFY_CONFIDENCE_THRESHOLD=0.7  # Flag claims below this confidence

# Source Tier Confidence Weights (applied to verification confidence scores)
# Tier 1 = peer-reviewed/government, Tier 2 = major news/official docs
# Tier 3 = community/wikis, Tier 4 = unknown/unvetted
# VERIFY_TIER_1_WEIGHT=1.0
# VERIFY_TIER_2_WEIGHT=0.95
# VERIFY_TIER_3_WEIGHT=0.85
# VERIFY_TIER_4_WEIGHT=0.75

# Two-Pass Report Generation (requires VERIFY_CLAIMS=true)
# Generates draft report, verifies claims, then revises to fix unsupported claims
# ENABLE_TWO_PASS=false              # Enable verification-based revision
# TWO_PASS_PRESERVE_DRAFT=true       # Save draft report with _draft suffix for comparison
# TWO_PASS_RE_VERIFY=true            # Re-verify after revision to ensure accuracy
# TWO_PASS_REVISION_THRESHOLD=0.0    # Revise if this ratio of claims fail (0.0=any failures, 0.3=30%+ failures)

# Gap Validation (validates declared limitations against final report)
# VALIDATE_GAPS=true  # Removes false limitations that are actually addressed

# Output Configuration
OUTPUT_DIR=./reports
LOG_LEVEL=INFO
REPORT_MAX_TOKENS=4000  # Default: ~3000 words
MAX_ITERATIONS=2  # Maximum research iterations (1=no iteration, 2=one additional iteration)

# Parallelization Configuration
# Control concurrent operations to balance speed vs rate limits
# Set to 1 to disable parallelization for that stage

# Search: Number of concurrent search queries
# Higher values = faster searching but more API load
# Recommended: 2-4 for most APIs, 1 if rate-limited
SEARCH_PARALLEL=2

# Scraping: Number of concurrent scrape operations
# Higher values = faster scraping but more network load
# Recommended: 5-10 for most sites, lower if rate-limited
SCRAPE_PARALLEL=5

# Summarization: Number of concurrent LLM calls
# Note: Same tokens = same cost regardless of parallelization
# Benefit: Same documents summarized in ~1/N time (N = number of workers)
# Risk: Concurrent requests may trigger rate limits if API tier is too low
# Recommendation: Start with 1-2, monitor for rate limit 429 errors
SUMMARY_PARALLEL=2
