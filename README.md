# Research Pipeline

A modular, configurable CLI tool for automated research report generation using LLMs.

**Source Code:** [https://github.com/jstevewhite/rsrch](https://github.com/jstevewhite/rsrch)

## Features

âœ… **Intent Classification**: Automatically identifies query type (informational, news, code, research, etc.)
âœ… **Research Planning**: Creates structured plans with sections and search queries
âœ… **Web Search Integration**: Searches the web using SERP API for current information
âœ… **Content Scraping**: Extracts and processes web content with fallback strategies
âœ… **Intelligent Summarization**: Generates summaries with citations using map-reduce
âœ… **Context Assembly**: Builds context packages with vector similarity and reranking
âœ… **Reflection & Iteration**: Validates completeness and performs additional research if needed
âœ… **Claim Verification**: Optional fact-checking of report claims (experimental)
âœ… **Configurable Models**: Use different LLMs for each stage via configuration
âœ… **Report Generation**: Produces comprehensive Markdown reports with citations

ðŸš§ **Advanced Features**:

- Vector database storage (SQLite + VSS) for semantic search
- Search result reranking for improved relevance
- Iterative research refinement based on reflection
- Multi-source claim verification with confidence scoring

## Architecture

The pipeline consists of 10 stages:

1. **Query Parsing**: Accept and parse user query
2. **Intent Classification**: Identify query intent
3. **Planning**: Design research approach and queries
4. **Research**: Execute web searches and gather results
5. **Scraping**: Extract and chunk content from URLs
6. **Summarization**: Generate summaries with citations
7. **Context Assembly**: Build context package with vector similarity
8. **Reflection**: Validate completeness and identify gaps
9. **Report Generation**: Create final report with citations
10. **Claim Verification**: Optional fact-checking (experimental)

## Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Copy and configure environment
cp .env.example .env
# Edit .env with your API keys
```

## Configuration

Configure the pipeline via `.env` file:

```bash
# API Configuration
API_KEY=your_openai_api_key
API_ENDPOINT=https://api.openai.com/v1
DEFAULT_MODEL=gpt-4o-mini

# Stage-Specific Models
INTENT_MODEL=gpt-4o-mini
PLANNER_MODEL=gpt-4o
MRS_MODEL=gpt-4o-mini
CONTEXT_MODEL=gpt-4o-mini
REFLECTION_MODEL=gpt-4o
REPORT_MODEL=gpt-4o
VERIFY_MODEL=gpt-4o

# Search Configuration
SERP_API_KEY=your_serp_api_key
RERANK_TOP_K=0.25

# Scraping Fallback (optional - for JS-heavy sites)
SERPER_API_KEY=your_serper_api_key
JINA_API_KEY=your_jina_api_key

# Vector Database Configuration
VECTOR_DB_PATH=./research_db.sqlite
EMBEDDING_MODEL=text-embedding-3-small

# Output Configuration
OUTPUT_DIR=./reports
LOG_LEVEL=INFO

# Research Configuration
MAX_ITERATIONS=3
VERIFY_CLAIMS=false
VERIFY_CONFIDENCE_THRESHOLD=0.7
```

## Usage

### Basic Usage

```bash
python cli.py "What is the latest research on tirzepatide?"
```

### Advanced Options

```bash
# Use custom config file
python cli.py "How do I initialize litellm in Python?" --config ./my_config.env

# Specify output directory
python cli.py "Israel/Gaza conflict latest news" --output ./my_reports

# Enable debug logging
python cli.py "Your query here" --log-level DEBUG

# Show research plan before execution
python cli.py "Your query here" --show-plan
```

### Example Queries

**Informational:**

```bash
python cli.py "What is the latest research on tirzepatide?"
```

**Code/Tutorial:**

```bash
python cli.py "How do you initialize litellm and use it in a python program?"
```

**News:**

```bash
python cli.py "What's the latest news on the Israel/Gaza conflict?"
```

**Research:**

```bash
python cli.py "Comparative analysis of transformer architectures for NLP tasks"
```

## Project Structure

```text
rsrch/
â”œâ”€â”€ cli.py                 # Main CLI entry point
â”œâ”€â”€ config.py             # Configuration management
â”œâ”€â”€ models.py             # Data models
â”œâ”€â”€ llm_client.py         # LLM client wrapper
â”œâ”€â”€ pipeline.py           # Pipeline orchestrator
â”œâ”€â”€ stages/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ intent_classifier.py    # Intent classification
â”‚   â”œâ”€â”€ planner.py              # Research planning
â”‚   â”œâ”€â”€ researcher.py           # Web search integration
â”‚   â”œâ”€â”€ scraper.py              # Content extraction & chunking
â”‚   â”œâ”€â”€ summarizer.py           # Map-reduce summarization
â”‚   â”œâ”€â”€ context_assembler.py   # Context building with vector search
â”‚   â”œâ”€â”€ reflector.py            # Completeness validation
â”‚   â”œâ”€â”€ reranker.py             # Search result reranking
â”‚   â”œâ”€â”€ verifier.py             # Claim verification (experimental)
â”‚   â”œâ”€â”€ content_detector.py     # Content type detection
â”‚   â””â”€â”€ embedding_client.py     # Embedding generation
â”œâ”€â”€ .env.example          # Example configuration
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
```

## Output

Reports are saved as Markdown files in the configured output directory (default: `./reports/`).

Example output file: `report_20250130_143022.md`

Each report includes:

- Query and intent
- Generation timestamp
- Structured content with sections
- Source citations with URLs and chunk references
- Research limitations (if incomplete)
- Metadata (intent, status, number of sources)

## Development Status

### Current Status (v1.0)

- âœ… Configuration system
- âœ… LLM client (OpenAI compatible)
- âœ… Intent classification (7 intent types)
- âœ… Research planning with structured sections
- âœ… Web search integration (SERP API)
- âœ… Content scraping with fallback strategies
- âœ… Vector database (SQLite + VSS)
- âœ… Map-reduce summarization with citations
- âœ… Context assembly with semantic search
- âœ… Reflection and iterative refinement
- âœ… Report generation with comprehensive citations
- âœ… Optional claim verification
- âœ… CLI interface with logging
- âœ… Comprehensive error handling

### Advanced Features Available

- **Search Reranking**: Improves result relevance using semantic similarity
- **Iterative Research**: Automatically performs additional research if gaps are identified
- **Claim Verification**: Fact-checks report claims against source material
- **Vector Storage**: Stores content chunks for semantic retrieval
- **Multi-Model Configuration**: Different LLMs for different pipeline stages

## Advanced Configuration

### Model Selection Strategy

The pipeline supports different models for different stages to optimize cost and performance:

```bash
# Fast, cost-effective models for simple tasks
INTENT_MODEL=gpt-4o-mini
MRS_MODEL=gpt-4o-mini
CONTEXT_MODEL=gpt-4o-mini

# More capable models for complex reasoning
PLANNER_MODEL=gpt-4o
REFLECTION_MODEL=gpt-4o
REPORT_MODEL=gpt-4o
```

### Scraping Strategy

The scraper uses a three-tier fallback approach:

1. **BeautifulSoup** (free) - Fast, lightweight HTML parsing
2. **Jina.ai** (paid) - Handles JavaScript and complex layouts
3. **Serper** (paid) - Professional scraping service

### Research Iteration

The pipeline can perform multiple research iterations:

- **Reflection** identifies information gaps
- **Additional queries** are generated to fill gaps
- **Maximum iterations** configurable (default: 3)
- **Stops early** if research is deemed complete

## Troubleshooting

### API Key Issues

- Ensure `API_KEY` is set in your `.env` file
- Check that the `.env` file is in the same directory as `cli.py`
- Verify your API keys are valid and have sufficient credits

### Module Import Errors

- Make sure you're running from the project root directory
- Install all requirements: `pip install -r requirements.txt`

### Search/Scraping Issues

- Verify `SERP_API_KEY` for web search functionality
- Optional: Configure `SERPER_API_KEY` or `JINA_API_KEY` for fallback scraping
- Check `research_pipeline.log` for detailed error messages

### Logging

- Check `research_pipeline.log` for detailed error messages
- Use `--log-level DEBUG` for verbose output
- Monitor scraping fallback usage and costs

## Contributing

This is an active development project. Key areas for contribution:

1. **Model Providers**: Add support for additional LLM providers (Anthropic, etc.)
2. **Search Sources**: Integrate additional search APIs or RSS feeds
3. **Scraping Strategies**: Improve content extraction for specific site types
4. **Verification**: Enhance claim verification accuracy and coverage
5. **UI/UX**: Create web interface or API endpoints
6. **Testing**: Unit and integration tests
7. **Performance**: Optimize vector operations and caching

## License

MIT

## Credits

Built on the foundation documented in `docs/pipeline.md`.
